# å¤šå‚è€ƒMAML-ANCå®ç° - åŸºäºMATLABç‰ˆæœ¬çš„å®Œæ•´å®ç°

import os
import numpy as np
import matplotlib.pyplot as plt
import scipy.io as sio
from scipy import signal
from scipy.io import wavfile

# ------------------- å¤šå‚è€ƒMAML-ANCæ ¸å¿ƒç®—æ³• -------------------
class MAML_ANC_Multi:
    """å¤šå‚è€ƒå¤šæ§åˆ¶æºMAML-ANCå®ç° (å¯¹åº”MATLABçš„MAML_Nstep_forget_MultiRef)"""
    
    def __init__(self, L, num_refs):
        """
        Args:
            L: æ»¤æ³¢å™¨é•¿åº¦ (æ¯ä¸ªé€šé“)
            num_refs: å‚è€ƒæºæ•°é‡
        """
        self.L = L
        self.num_refs = num_refs
        # æƒé‡ä¸ºå †å å‘é‡ [L*num_refs Ã— 1]ï¼Œä¸MATLABä¿æŒä¸€è‡´
        self.Phi = np.zeros(L * num_refs)
        
    def maml_update(self, Fx_input, Di_input, mu, lamda, epsilon):
        """
        Fx_input: [L, num_refs]  æ¯åˆ—ä¸€æ¡å‚è€ƒçš„ filtered-x
        Di_input: [L]
        """
        L = self.L
        K = self.num_refs

        # âœ… å…³é”®ï¼šä¿æŒ 2Dï¼Œå†æŒ‰â€œæ—¶é—´è½´â€ç¿»è½¬
        F = np.flipud(Fx_input)          # [L, K]ï¼Œåªåœ¨æ—¶é—´ç»´åº¦ä¸Šä¸‹ç¿»
        D = np.flipud(Di_input)          # [L]

        F_vec = F.flatten('F')           # [L*K]ï¼ŒæŒ‰åˆ—å †å 
        e0 = D[0] - np.dot(self.Phi, F_vec)
        Wo = self.Phi + mu * e0 * F_vec  # å†…å±‚ä¸€æ­¥

        Grad = np.zeros_like(self.Phi)
        Er = 0.0

        for jj in range(L):
            if jj == 0:
                Fd = F
            else:
                # æ¯åˆ—å„è‡ªå‘ä¸‹ç§»ä½ï¼ˆæ—¶é—´å¯¹é½ï¼‰ï¼Œåˆ—ä¸äº’æ¢
                Fd = np.vstack([F[jj:, :], np.zeros((jj, K))])  # [L, K]

            Fd_vec = Fd.flatten('F')      # [L*K]
            e = D[jj] - np.dot(Wo, Fd_vec)
            Grad += epsilon * (mu / L) * e * Fd_vec * (lamda ** jj)

            if jj == 0:
                Er = e

        self.Phi += Grad
        return Er


def resample_to_target(x: np.ndarray, fs_orig: int, fs_target: int) -> np.ndarray:
    """é‡é‡‡æ ·å‡½æ•°"""
    if fs_orig == fs_target:
        return x
    return signal.resample_poly(x, fs_target, fs_orig, axis=0)


def FxLMS_MultiRef(Len_N, Wc, Dis, Rf, muw):
    """
    å¤šå‚è€ƒFxLMSç®—æ³•å®ç°ï¼ˆå¯¹åº”MATLABçš„FxLMS_MultiRefï¼‰
    
    Args:
        Len_N: æ»¤æ³¢å™¨é•¿åº¦
        Wc: æ§åˆ¶æ»¤æ³¢å™¨æƒé‡ [Len_N*num_refs]
        Dis: å¹²æ‰°ä¿¡å· [N]
        Rf: å¤šé€šé“filteredå‚è€ƒä¿¡å· [N, num_refs]
        muw: æ­¥é•¿
    
    Returns:
        Er: è¯¯å·®ä¿¡å· [N]
        W_final: æœ€ç»ˆæƒé‡
    """
    N = len(Dis)
    num_refs = Rf.shape[1]
    
    # åˆå§‹åŒ–
    W = Wc.copy()
    Er = np.zeros(N)
    
    # å‚è€ƒä¿¡å·ç¼“å­˜ [Len_N, num_refs]
    ref_buffer = np.zeros((Len_N, num_refs))
    
    for n in range(N):
        # æ›´æ–°ç¼“å­˜
        ref_buffer = np.roll(ref_buffer, 1, axis=0)
        ref_buffer[0, :] = Rf[n, :]
        
        # å †å æˆåˆ—å‘é‡ï¼ˆä¸MATLABä¸€è‡´ï¼‰
        ref_stacked = ref_buffer.flatten('F')  # æŒ‰åˆ—ä¼˜å…ˆ
        
        # è®¡ç®—æ§åˆ¶ä¿¡å·
        control_signal = np.dot(W, ref_stacked)
        
        # è®¡ç®—è¯¯å·®
        Er[n] = Dis[n] - control_signal
        
        # æ›´æ–°æƒé‡
        W = W + muw * Er[n] * ref_stacked
    
    return Er, W


# ================= é…ç½®å‚æ•° =================
fs = 16000
T = 3
N = fs * T
Len_N = 512
NUM_REFS = 2  # åŒå‚è€ƒ

# MAMLå‚æ•°
NUM_EPOCHS = 4096 * 5  # ä¸MATLABä¸€è‡´
MU = 0.003
LAMBDA = 0.99
EPSILON = 0.5

# è·¯å¾„é…ç½®
PATH_DIR = 'E:/NTU/Test/HeadphonePathMeasurement/Recording/Primary/PriPathModels_E'

# è®­ç»ƒæ–‡ä»¶åˆ—è¡¨ï¼ˆä¸MATLABä¸€è‡´ï¼‰
TRAIN_FILES = [
    'PriPath_Pri_d50_180.mat',
]

SEC_PATH_FILE = 'E:/NTU/Test/HeadphonePathMeasurement/Recording/Secondary/SecPathModels/SecPath_firmed.mat'
TEST_NOISE_PATH = r'E:\NTU\AIANC\Meta-main\bandpassed_200_700.wav'

print("=" * 60)
print(f"Multi-Reference MAML-ANC (2 References)")
print(f"Configuration: {NUM_REFS} references, {len(TRAIN_FILES)} training paths")
print("=" * 60)

# ================= åŠ è½½è®­ç»ƒè·¯å¾„ =================
print("ğŸ”„ Loading training paths...")

all_ref_path = []  # å­˜å‚¨æ‰€æœ‰çš„å‚è€ƒè·¯å¾„å¯¹ [refL, refR]
all_err_path = []  # å­˜å‚¨æ‰€æœ‰çš„è¯¯å·®è·¯å¾„

for fname in TRAIN_FILES:
    file_path = os.path.join(PATH_DIR, fname)
    if not os.path.exists(file_path):
        print(f"âš ï¸ Warning: Training file not found: {file_path}")
        continue
    
    dat = sio.loadmat(file_path)
    G = dat["G_matrix"]  # 4åˆ—ï¼šLL, LR, RL, RR
    
    # æå–è·¯å¾„ï¼ˆä¸MATLABå¯¹åº”ï¼‰
    # G(:,1) = ch1â†’ch2 (ç”µâ†’refL)
    # G(:,2) = ch1â†’ch3 (ç”µâ†’refR) 
    # G(:,3) = ch1â†’ch4 (ç”µâ†’errL)
    h_refL = resample_to_target(G[:, 0], 48000, fs)  # ç¬¬1åˆ—
    h_refR = resample_to_target(G[:, 1], 48000, fs)  # ç¬¬2åˆ—
    h_err = resample_to_target(G[:, 2], 48000, fs)   # ç¬¬3åˆ—
    
    # å­˜å‚¨ä¸º[refL, refR]å¯¹
    all_ref_path.append([h_refL, h_refR])
    all_err_path.append(h_err)

print(f"âœ… Loaded {len(all_ref_path)} training path sets")

# åŠ è½½æ¬¡çº§è·¯å¾„
if not os.path.exists(SEC_PATH_FILE):
    raise FileNotFoundError(f"Secondary path file not found: {SEC_PATH_FILE}")

sec_dat = sio.loadmat(SEC_PATH_FILE)
sec_keys = [k for k in sec_dat.keys() if not k.startswith('__')]
sec_key = sec_keys[0]
S_data = sec_dat[sec_key]
S_48k = S_data[:, 0]  # ä½¿ç”¨ç¬¬1åˆ—
S = resample_to_target(S_48k, 48000, fs)

print(f"âœ… Secondary path loaded, length: {len(S)}")

# ================= ç”Ÿæˆè®­ç»ƒæ•°æ® =================
print(f"\nğŸ”„ Generating training samples for {NUM_REFS} references...")

# ç”Ÿæˆç™½å™ªå£°
white = np.random.randn(N)

# å®½å¸¦æ»¤æ³¢å™¨ï¼ˆå¯¹åº”MATLABçš„broadband_filterï¼‰
nyquist = fs / 2
broadband_filter = signal.firwin(512, [0.015, 0.25], pass_zero=False, window='hamming')
# 0.015 * 8000 = 120Hz, 0.25 * 8000 = 2000Hz

# å‡†å¤‡è®­ç»ƒæ•°æ®å­˜å‚¨
Fx_data = np.zeros((Len_N * NUM_REFS, NUM_EPOCHS))  # [2*Len_N, N_epochs]
Di_data = np.zeros((Len_N, NUM_EPOCHS))

print("Generating training samples...")
for jj in range(NUM_EPOCHS):
    if (jj + 1) % (NUM_EPOCHS // 10) == 0:
        print(f"  Progress: {jj + 1}/{NUM_EPOCHS}")
    
    # éšæœºé€‰æ‹©è·¯å¾„ï¼ˆå¯¹åº”MATLAB: idx = randi(length(train_files))ï¼‰
    idx = np.random.randint(len(all_ref_path))
    P_ref = all_ref_path[idx]  # [refL, refR]
    P_err = all_err_path[idx]
    
    # åˆ†ç¦»refLå’ŒrefR
    P_ref_L = P_ref[0]
    P_ref_R = P_ref[1]
    
    # ç”Ÿæˆå®½å¸¦å™ªå£°
    broadband = signal.lfilter(broadband_filter, [1.0], white)
    
    # æ§åˆ¶è¾“å…¥è·¯å¾„ï¼ˆå‚è€ƒä¿¡å·ï¼‰
    x_ref_L = signal.lfilter(P_ref_L, [1.0], broadband)  # ç”µâ†’refL
    x_ref_R = signal.lfilter(P_ref_R, [1.0], broadband)  # ç”µâ†’refR
    xprime_L = signal.lfilter(S, [1.0], x_ref_L)         # refLâ†’err
    xprime_R = signal.lfilter(S, [1.0], x_ref_R)         # refRâ†’err
    
    # è¯¯å·®ä¿¡å·è·¯å¾„
    d = signal.lfilter(P_err, [1.0], broadband)          # ç”µâ†’err
    
    # éšæœºè£å‰ªï¼ˆå¯¹åº”MATLAB: idx_cut = randi([Len_N, length(d)])ï¼‰
    idx_cut = np.random.randint(Len_N, len(d))
    
    # å­˜å‚¨æ•°æ®
    Di_data[:, jj] = d[idx_cut - Len_N:idx_cut]
    
    # æ‹¼æ¥2é€šé“å‚è€ƒä¿¡å·ï¼ˆå‚ç›´æ‹¼æ¥ï¼‰
    x1 = xprime_L[idx_cut - Len_N:idx_cut]
    x2 = xprime_R[idx_cut - Len_N:idx_cut]
    Fx_data[:, jj] = np.concatenate([x1, x2])  # [2*Len_N]

print(f"âœ… Training data shape: Fx_data {Fx_data.shape}, Di_data {Di_data.shape}")

# ================= MAMLè®­ç»ƒ =================
print(f"\nğŸ”„ Training Multi-Reference MAML with {NUM_REFS} references...")

maml_anc = MAML_ANC_Multi(Len_N, NUM_REFS)
Er_train = []

for jj in range(NUM_EPOCHS):
    # å‡†å¤‡è¾“å…¥æ•°æ®
    Fx_input_stacked = Fx_data[:, jj]  # [2*Len_N]
    Fx_input = Fx_input_stacked.reshape(NUM_REFS, Len_N).T  # [Len_N, 2]
    Di_input = Di_data[:, jj]  # [Len_N]
    
    Er = maml_anc.maml_update(Fx_input, Di_input, MU, LAMBDA, EPSILON)
    Er_train.append(Er)
    
    if (jj + 1) % (NUM_EPOCHS // 20) == 0 or jj == 0:
        weight_energy = np.sum(maml_anc.Phi**2)
        print(f"Epoch {jj + 1}: Er = {Er:.6f}, Weight energy = {weight_energy:.6f}")

# è·å–æœ€ç»ˆæƒé‡
Wc = maml_anc.Phi  # [2*Len_N]

print(f"\nâœ… Multi-Reference MAML training completed!")
print(f"Final weights shape: {Wc.shape}")
print(f"Weight statistics:")
print(f"  RefL weights - Mean: {np.mean(Wc[:Len_N]):.6f}, Energy: {np.sum(Wc[:Len_N]**2):.6f}")
print(f"  RefR weights - Mean: {np.mean(Wc[Len_N:]):.6f}, Energy: {np.sum(Wc[Len_N:]**2):.6f}")

# ================= æµ‹è¯•æ•°æ®å‡†å¤‡ =================
print("\nğŸ”„ Preparing test data...")

# åŠ è½½æµ‹è¯•å™ªå£°
if not os.path.exists(TEST_NOISE_PATH):
    raise FileNotFoundError(f"Test noise file not found: {TEST_NOISE_PATH}")

fs_orig, test_audio_raw = wavfile.read(TEST_NOISE_PATH)

# è½¬æ¢å¹¶å½’ä¸€åŒ–
if test_audio_raw.dtype == np.int16:
    Pri_1 = test_audio_raw.astype(np.float32) / 32768.0
else:
    Pri_1 = test_audio_raw.astype(np.float32)

if Pri_1.ndim > 1:
    Pri_1 = Pri_1[:, 0]

# é‡é‡‡æ ·åˆ°16kHz
if fs_orig != fs:
    Pri_1 = resample_to_target(Pri_1, fs_orig, fs)

print(f"âœ… Test noise loaded: {len(Pri_1)} samples")

# ä½¿ç”¨d20_90ä½œä¸ºæµ‹è¯•è·¯å¾„ï¼ˆå¯¹åº”MATLABï¼‰
test_file = 'PriPath_Pri_d50_180.mat'
test_path = os.path.join(PATH_DIR, test_file)

if not os.path.exists(test_path):
    print(f"âš ï¸ Test file not found: {test_path}, using first training file instead")
    test_path = os.path.join(PATH_DIR, TRAIN_FILES[0])

test_data = sio.loadmat(test_path)
G_test = test_data["G_matrix"]

# æ„é€ ä¸¤ä¸ªå‚è€ƒè·¯å¾„
P_refL_test = resample_to_target(G_test[:, 0], 48000, fs)  # ch1â†’ch2
P_refR_test = resample_to_target(G_test[:, 1], 48000, fs)  # ch1â†’ch3
P_err_test = resample_to_target(G_test[:, 2], 48000, fs)   # ch1â†’ch4

# å‚è€ƒé€šé“åˆ†åˆ«é€šè¿‡å„è‡ªè·¯å¾„
x_refL = signal.lfilter(P_refL_test, [1.0], Pri_1)  # ç”µâ†’refL
x_refR = signal.lfilter(P_refR_test, [1.0], Pri_1)  # ç”µâ†’refR

# é€šè¿‡æ¬¡çº§è·¯å¾„S
Rf_L = signal.lfilter(S, [1.0], x_refL)
Rf_R = signal.lfilter(S, [1.0], x_refR)
Rf_test = np.column_stack([Rf_L, Rf_R])  # [N, 2] åŒé€šé“å‚è€ƒ

# æ„é€ è¯¯å·®ä¿¡å·
Dis_1 = signal.lfilter(P_err_test, [1.0], Pri_1)

print(f"âœ… Test signals generated: Rf_test shape {Rf_test.shape}, Dis_1 length {len(Dis_1)}")

# ================= FxLMSæµ‹è¯• =================
print("\nğŸ“Š Running FxLMS tests...")

# 1. é›¶åˆå§‹åŒ–
Wc_zero = np.zeros(2 * Len_N)
muw = 0.00001
print("  Testing zero-init FxLMS...")
Er_zero, _ = FxLMS_MultiRef(Len_N, Wc_zero, Dis_1, Rf_test, muw)

# 2. MAMLåˆå§‹åŒ–
print("  Testing MAML-init FxLMS...")
Er_maml, _ = FxLMS_MultiRef(Len_N, Wc, Dis_1, Rf_test, 5*muw)

# 3. Normalizeåˆå§‹åŒ–ï¼ˆä¸MATLABå¯¹åº”ï¼‰
fan_in = Len_N
fan_out = Len_N * 2
limit = np.sqrt(6) / 512
Wc_norm = (2 * np.random.rand(2 * Len_N) - 1) * limit
print("  Testing Normalize-init FxLMS...")
Er_norm, _ = FxLMS_MultiRef(Len_N, Wc_norm, Dis_1, Rf_test, muw)

print("âœ… FxLMS tests completed!")

# ================= ç»“æœåˆ†æ =================
print("\n" + "=" * 60)
print("Multi-Reference Results Analysis")
print("=" * 60)

def compute_mse_db(signal, L0=94):
    """è®¡ç®—MSEï¼ˆdB SPLï¼‰"""
    return 10 * np.log10(np.mean(signal**2) + 1e-10) + L0

# è®¡ç®—å¹³å‡MSE
L0 = 94  # å‚è€ƒSPLåŸºå‡†
avg_off = compute_mse_db(Dis_1, L0)
avg_zero = compute_mse_db(Er_zero, L0)
avg_norm = compute_mse_db(Er_norm, L0)
avg_maml = compute_mse_db(Er_maml, L0)

print("ğŸ“Š Average MSE (dB SPL) on test position:")
print(f"  ANC off:           {avg_off:.2f} dB")
print(f"  Zero-init:         {avg_zero:.2f} dB")
print(f"  Normalize-init:    {avg_norm:.2f} dB")
print(f"  MAML-init:         {avg_maml:.2f} dB")
print(f"  MAML improvement:  {avg_zero - avg_maml:.2f} dB")

# ================= å¯è§†åŒ– =================
print("\nğŸ”„ Creating visualizations...")

plt.figure(figsize=(18, 12))

# 1. è®­ç»ƒè¯¯å·®æ›²çº¿
plt.subplot(3, 4, 1)
plt.plot(Er_train)
plt.title('Multi-Ref MAML Training Error')
plt.xlabel('Epoch')
plt.ylabel('Training Error')
plt.grid(True)

# 2. MAMLæƒé‡ï¼ˆåˆ†é€šé“æ˜¾ç¤ºï¼‰
plt.subplot(3, 4, 2)
plt.plot(Wc[:Len_N], label='RefL weights', alpha=0.8)
plt.plot(Wc[Len_N:], label='RefR weights', alpha=0.8)
plt.title('MAML Weights (2 References)')
plt.xlabel('Coefficient Index')
plt.ylabel('Weight Value')
plt.legend()
plt.grid(True)

# 3. æ—¶åŸŸä¿¡å·æ¯”è¾ƒ
plt.subplot(3, 4, 3)
t = np.arange(min(10000, len(Dis_1))) / fs
plt.plot(t, Dis_1[:len(t)], 'k', label='ANC off', alpha=0.7)
plt.plot(t, Er_zero[:len(t)], 'b--', label='Zero-init', alpha=0.8)
plt.plot(t, Er_norm[:len(t)], 'g', label='Norm-init', alpha=0.8)
plt.plot(t, Er_maml[:len(t)], 'r', label='MAML-init', alpha=0.8)
plt.title('Time Domain Comparison')
plt.xlabel('Time (s)')
plt.ylabel('Amplitude')
plt.legend()
plt.grid(True)

# 4. MSEå¯¹æ¯”æŸ±çŠ¶å›¾
plt.subplot(3, 4, 4)
categories = ['ANC off', 'Zero', 'Normalize', 'MAML']
mse_values = [avg_off, avg_zero, avg_norm, avg_maml]
colors = ['black', 'blue', 'green', 'red']
bars = plt.bar(categories, mse_values, color=colors, alpha=0.7)
plt.title('Average MSE Comparison')
plt.ylabel('MSE (dB SPL)')
plt.ylim([40, 100])
plt.grid(True, alpha=0.3)
for bar, val in zip(bars, mse_values):
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
             f'{val:.1f}', ha='center', va='bottom')

# 5. æ»‘åŠ¨MSEæ›²çº¿
plt.subplot(3, 4, 5)
win_len = 4096

# ä½¿ç”¨æ»‘åŠ¨å¹³å‡è®¡ç®—MSE
from scipy.ndimage import uniform_filter1d
mse_off = 10*np.log10(uniform_filter1d(Dis_1**2, win_len, mode='constant') + 1e-10) + L0
mse_zero = 10*np.log10(uniform_filter1d(Er_zero**2, win_len, mode='constant') + 1e-10) + L0
mse_maml = 10*np.log10(uniform_filter1d(Er_maml**2, win_len, mode='constant') + 1e-10) + L0

t_mse = np.arange(len(Dis_1)) / fs
plt.plot(t_mse, mse_off, 'k', linewidth=2, label='ANC off')
plt.plot(t_mse, mse_zero, 'b--', linewidth=2, label='Zero-init')
plt.plot(t_mse, mse_maml, 'r', linewidth=2, label='MAML-init')
plt.title('MSE Evolution (dB SPL)')
plt.xlabel('Time (s)')
plt.ylabel('MSE (dB)')
plt.ylim([45, 95])
plt.legend()
plt.grid(True)

# 6. é¢‘è°±åˆ†æ
plt.subplot(3, 4, 6)
# æå–ç¨³æ€éƒ¨åˆ†ï¼ˆååŠæ®µï¼‰
E_tail_off = Dis_1[len(Dis_1)//2:]
E_tail_zero = Er_zero[len(Er_zero)//2:]
E_tail_maml = Er_maml[len(Er_maml)//2:]

# Welché¢‘è°±ä¼°è®¡
nfft = 2048
f, Pxx_off = signal.welch(E_tail_off, fs=fs, nperseg=nfft)
_, Pxx_zero = signal.welch(E_tail_zero, fs=fs, nperseg=nfft)
_, Pxx_maml = signal.welch(E_tail_maml, fs=fs, nperseg=nfft)

# è½¬ä¸ºSPL
sensitivity = 36
L0_spec = 20*np.log10(5e4*11.9/sensitivity) + 40
SPL_off = L0_spec + 10*np.log10(Pxx_off)
SPL_zero = L0_spec + 10*np.log10(Pxx_zero)
SPL_maml = L0_spec + 10*np.log10(Pxx_maml)

plt.plot(f, SPL_off, 'k', linewidth=1.8, label='ANC off')
plt.plot(f, SPL_zero, 'b--', linewidth=1.8, label='Zero-init')
plt.plot(f, SPL_maml, 'r', linewidth=1.8, label='MAML-init')
plt.xlabel('Frequency (Hz)')
plt.ylabel('SPL (dB)')
plt.xlim([20, 1000])
plt.ylim([-30, 100])
plt.legend()
plt.grid(True)

# 7. æƒé‡èƒ½é‡åˆ†å¸ƒ
plt.subplot(3, 4, 7)
energy_L = np.sum(Wc[:Len_N]**2)
energy_R = np.sum(Wc[Len_N:]**2)
plt.bar(['RefL', 'RefR'], [energy_L, energy_R], alpha=0.7)
plt.title('Weight Energy Distribution')
plt.ylabel('Energy')
plt.grid(True, alpha=0.3)

# 8. æƒé‡ç›¸å…³æ€§
plt.subplot(3, 4, 8)
corr = np.corrcoef(Wc[:Len_N], Wc[Len_N:])[0, 1]
plt.text(0.5, 0.5, f'Correlation: {corr:.3f}', 
         fontsize=14, ha='center', va='center')
plt.title('RefL-RefR Weight Correlation')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.axis('off')

# 9. è®­ç»ƒæ”¶æ•›ï¼ˆæ»‘åŠ¨å¹³å‡ï¼‰
plt.subplot(3, 4, 9)
if len(Er_train) > 100:
    window_train = max(50, len(Er_train) // 50)
    moving_avg = np.convolve(Er_train, np.ones(window_train)/window_train, mode='valid')
    plt.plot(moving_avg, linewidth=2)
    plt.title('Training Convergence (Moving Avg)')
    plt.xlabel('Epoch')
    plt.ylabel('Error')
    plt.grid(True)

# 10. æ”¹è¿›æ€»ç»“
plt.subplot(3, 4, 10)
improvements = [
    avg_zero - avg_maml,
    avg_norm - avg_maml,
]
plt.bar(['vs Zero-init', 'vs Norm-init'], improvements, alpha=0.7, color=['blue', 'green'])
plt.title('MAML Improvements (dB)')
plt.ylabel('Improvement (dB)')
plt.axhline(y=0, color='black', linestyle='-', alpha=0.5)
plt.grid(True, alpha=0.3)
for i, val in enumerate(improvements):
    plt.text(i, val + (0.1 if val >= 0 else -0.3),
             f'{val:.2f}', ha='center', va='bottom' if val >= 0 else 'top')

# 11. æƒé‡é¢‘ç‡å“åº”
plt.subplot(3, 4, 11)
w_L, h_L = signal.freqz(Wc[:Len_N], worN=512, fs=fs)
w_R, h_R = signal.freqz(Wc[Len_N:], worN=512, fs=fs)
plt.plot(w_L, 20*np.log10(np.abs(h_L)), label='RefL filter')
plt.plot(w_R, 20*np.log10(np.abs(h_R)), label='RefR filter')
plt.title('Filter Frequency Response')
plt.xlabel('Frequency (Hz)')
plt.ylabel('Magnitude (dB)')
plt.xlim([0, 2000])
plt.legend()
plt.grid(True)

# 12. æ”¶æ•›é€Ÿåº¦æ¯”è¾ƒ
plt.subplot(3, 4, 12)
# è®¡ç®—ç´¯ç§¯è¯¯å·®èƒ½é‡
cumsum_zero = np.cumsum(Er_zero**2)
cumsum_maml = np.cumsum(Er_maml**2)
t_cum = np.arange(len(Er_zero)) / fs
plt.plot(t_cum, cumsum_zero/cumsum_zero[-1], 'b--', label='Zero-init', linewidth=2)
plt.plot(t_cum, cumsum_maml/cumsum_maml[-1], 'r', label='MAML-init', linewidth=2)
plt.title('Normalized Cumulative Error Energy')
plt.xlabel('Time (s)')
plt.ylabel('Normalized Energy')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.savefig('multi_ref_maml_results.png', dpi=300, bbox_inches='tight')
plt.show()

# ================= é¢å¤–æµ‹è¯•ï¼šä½¿ç”¨FxLMSè®­ç»ƒå•ä¸ªä½ç½® =================
print("\n" + "=" * 60)
print("Additional Test: Single-task FxLMS Training")
print("=" * 60)

# é€‰æ‹©ä¸€ä¸ªè®­ç»ƒä½ç½®ï¼ˆå¦‚d20_180ï¼‰è¿›è¡ŒFxLMSè®­ç»ƒ
single_task_file = 'PriPath_Pri_d20_180.mat'
single_task_path = os.path.join(PATH_DIR, single_task_file)

if os.path.exists(single_task_path):
    print(f"ğŸ”„ Training FxLMS on single position: {single_task_file}")
    
    # åŠ è½½å•ä»»åŠ¡è·¯å¾„
    d20_data = sio.loadmat(single_task_path)
    G_d20 = d20_data["G_matrix"]
    
    P_refL_d20 = resample_to_target(G_d20[:, 0], 48000, fs)
    P_refR_d20 = resample_to_target(G_d20[:, 1], 48000, fs)
    P_err_d20 = resample_to_target(G_d20[:, 2], 48000, fs)
    
    # ç”Ÿæˆè®­ç»ƒä¿¡å·ï¼ˆä½¿ç”¨ç›¸åŒçš„å®½å¸¦å™ªå£°ï¼‰
    x_train = signal.lfilter(broadband_filter, [1.0], np.random.randn(N))
    
    x_refL_train = signal.lfilter(P_refL_d20, [1.0], x_train)
    x_refR_train = signal.lfilter(P_refR_d20, [1.0], x_train)
    Rf_L_train = signal.lfilter(S, [1.0], x_refL_train)
    Rf_R_train = signal.lfilter(S, [1.0], x_refR_train)
    Rf_train = np.column_stack([Rf_L_train, Rf_R_train])
    
    Dis_train = signal.lfilter(P_err_d20, [1.0], x_train)
    
    # è®­ç»ƒFxLMS
    Wc_init_d20 = np.zeros(2 * Len_N)
    muw_train = 0.002
    print("  Training single-task FxLMS...")
    Er_d20_train, W_d20 = FxLMS_MultiRef(Len_N, Wc_init_d20, Dis_train, Rf_train, muw_train)
    
    # åœ¨æµ‹è¯•ä½ç½®åº”ç”¨
    print("  Testing single-task FxLMS on test position...")
    muw_test = 0.001
    Er_d20, _ = FxLMS_MultiRef(Len_N, W_d20, Dis_1, Rf_test, muw_test)
    
    # è®¡ç®—æ€§èƒ½
    avg_d20 = compute_mse_db(Er_d20, L0)
    print(f"\nğŸ“Š Single-task FxLMS Results:")
    print(f"  Single-task init:  {avg_d20:.2f} dB")
    print(f"  vs Zero-init:      {avg_zero - avg_d20:.2f} dB improvement")
    print(f"  vs MAML-init:      {avg_d20 - avg_maml:.2f} dB worse than MAML")
    
    # æ·»åŠ åˆ°æœ€ç»ˆæ¯”è¾ƒå›¾
    plt.figure(figsize=(12, 8))
    
    # æ—¶åŸŸæ¯”è¾ƒ
    plt.subplot(2, 2, 1)
    t_plot = np.arange(min(20000, len(Dis_1))) / fs
    plt.plot(t_plot, Dis_1[:len(t_plot)], 'k', label='ANC off', alpha=0.6, linewidth=1)
    plt.plot(t_plot, Er_zero[:len(t_plot)], 'b--', label='Zero-init', alpha=0.7, linewidth=1)
    plt.plot(t_plot, Er_d20[:len(t_plot)], 'orange', label='Single-task', alpha=0.8, linewidth=1.5)
    plt.plot(t_plot, Er_maml[:len(t_plot)], 'r', label='MAML-init', alpha=0.8, linewidth=1.5)
    plt.title('Final Comparison: Time Domain')
    plt.xlabel('Time (s)')
    plt.ylabel('Amplitude')
    plt.legend()
    plt.grid(True)
    
    # MSEæ¯”è¾ƒ
    plt.subplot(2, 2, 2)
    categories_final = ['ANC off', 'Zero', 'Single-task', 'MAML']
    mse_values_final = [avg_off, avg_zero, avg_d20, avg_maml]
    colors_final = ['black', 'blue', 'orange', 'red']
    bars = plt.bar(categories_final, mse_values_final, color=colors_final, alpha=0.7)
    plt.title('Final MSE Comparison (dB SPL)')
    plt.ylabel('MSE (dB)')
    plt.ylim([40, 100])
    plt.grid(True, alpha=0.3)
    for bar, val in zip(bars, mse_values_final):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                 f'{val:.1f}', ha='center', va='bottom')
    
    # æ»‘åŠ¨MSEæ›²çº¿
    plt.subplot(2, 2, 3)
    mse_d20 = 10*np.log10(uniform_filter1d(Er_d20**2, win_len, mode='constant') + 1e-10) + L0
    
    plt.plot(t_mse, mse_off, 'k', linewidth=2, label='ANC off')
    plt.plot(t_mse, mse_zero, 'b--', linewidth=2, label='Zero-init')
    plt.plot(t_mse, mse_d20, 'orange', linewidth=2, label='Single-task')
    plt.plot(t_mse, mse_maml, 'r', linewidth=2, label='MAML-init')
    plt.title('MSE Evolution with Single-task')
    plt.xlabel('Time (s)')
    plt.ylabel('MSE (dB SPL)')
    plt.ylim([45, 95])
    plt.legend(loc='best')
    plt.grid(True)
    
    # é¢‘è°±æ¯”è¾ƒ
    plt.subplot(2, 2, 4)
    E_tail_d20 = Er_d20[len(Er_d20)//2:]
    _, Pxx_d20 = signal.welch(E_tail_d20, fs=fs, nperseg=nfft)
    SPL_d20 = L0_spec + 10*np.log10(Pxx_d20)
    
    plt.plot(f, SPL_off, 'k', linewidth=1.8, label='ANC off')
    plt.plot(f, SPL_zero, 'b--', linewidth=1.8, label='Zero-init')
    plt.plot(f, SPL_d20, 'orange', linewidth=1.8, label='Single-task')
    plt.plot(f, SPL_maml, 'r', linewidth=1.8, label='MAML-init')
    plt.xlabel('Frequency (Hz)')
    plt.ylabel('SPL (dB)')
    plt.xlim([20, 1000])
    plt.ylim([-30, 100])
    plt.legend(loc='best')
    plt.grid(True)
    
    plt.suptitle('Multi-Reference MAML vs Single-task Learning', fontsize=14)
    plt.tight_layout()
    plt.savefig('maml_vs_single_task.png', dpi=300, bbox_inches='tight')
    plt.show()

else:
    print(f"âš ï¸ Single-task file not found: {single_task_path}")

# ================= æœ€ç»ˆæ€»ç»“ =================
print("\n" + "=" * 60)
print("FINAL SUMMARY - Multi-Reference MAML-ANC")
print("=" * 60)
print(f"\nğŸ“Š Configuration:")
print(f"  - References: {NUM_REFS}")
print(f"  - Filter length: {Len_N}")
print(f"  - Training paths: {len(TRAIN_FILES)}")
print(f"  - Training epochs: {NUM_EPOCHS}")
print(f"  - MAML parameters: Î¼={MU}, Î»={LAMBDA}, Îµ={EPSILON}")

print(f"\nğŸ“Š Performance Summary (dB SPL):")
print(f"  {'Method':<20} {'MSE':<10} {'vs Zero':<12} {'vs MAML':<12}")
print(f"  {'-'*54}")
print(f"  {'ANC off':<20} {avg_off:>8.2f}")
print(f"  {'Zero-init':<20} {avg_zero:>8.2f} {'':<12} {avg_zero-avg_maml:>10.2f}")
print(f"  {'Normalize-init':<20} {avg_norm:>8.2f} {avg_zero-avg_norm:>10.2f} {avg_norm-avg_maml:>10.2f}")
if 'avg_d20' in locals():
    print(f"  {'Single-task':<20} {avg_d20:>8.2f} {avg_zero-avg_d20:>10.2f} {avg_d20-avg_maml:>10.2f}")
print(f"  {'MAML-init':<20} {avg_maml:>8.2f} {avg_zero-avg_maml:>10.2f} {'':<12} âœ…")

print(f"\nğŸ“Š Key Findings:")
print(f"  - MAML provides {avg_zero-avg_maml:.2f} dB improvement over zero-init")
print(f"  - MAML provides {avg_norm-avg_maml:.2f} dB improvement over normalize-init")
if 'avg_d20' in locals():
    print(f"  - MAML provides {avg_d20-avg_maml:.2f} dB improvement over single-task learning")
print(f"  - Weight energy: RefL={np.sum(Wc[:Len_N]**2):.4f}, RefR={np.sum(Wc[Len_N:]**2):.4f}")
print(f"  - Weight correlation: {np.corrcoef(Wc[:Len_N], Wc[Len_N:])[0,1]:.3f}")

print("\nâœ… Multi-Reference MAML-ANC Implementation Completed Successfully!")
print("=" * 60)